{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Evaluation for pre-trained models\n",
    "Models selected for object detection:\n",
    "1. [ultralytics/yolov5](https://pytorch.org/hub/ultralytics_yolov5/) - YOLOv5s\n",
    "2. [detr resnet 50](https://huggingface.co/facebook/detr-resnet-50)\n",
    "3. [fasterrcnn_resnet50_fpn_v2](https://pytorch.org/vision/0.20/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn_v2.html#fasterrcnn-resnet50-fpn-v2)\n",
    "4. [retinanet_resnet50_fpn_v2](https://pytorch.org/vision/0.20/models/generated/torchvision.models.detection.retinanet_resnet50_fpn_v2.html#retinanet-resnet50-fpn-v2)\n",
    "\n",
    "But also YoLoV11 from the official [repo](https://github.com/ultralytics/ultralytics)."
   ],
   "id": "f548da5dea87c03d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:22.525436Z",
     "start_time": "2024-11-16T09:54:18.929740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from my_utils.dataset_loader import ObjectDetectionDataset, DatasetMode, simple_collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import (\n",
    "    f1_score, precision_score, recall_score,\n",
    "    average_precision_score, roc_auc_score,\n",
    "    multilabel_confusion_matrix\n",
    ")\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "66272670142e362f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:23.089594Z",
     "start_time": "2024-11-16T09:54:23.086802Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir = \"D:\\\\Projects\\\\ml-ops-wildlife\\\\data\\\\WAID\"",
   "id": "eefc703f968c4038",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:23.481114Z",
     "start_time": "2024-11-16T09:54:23.450939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "id": "313125ba22843747",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:24.122465Z",
     "start_time": "2024-11-16T09:54:23.798092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_dataset = ObjectDetectionDataset(data_dir, DatasetMode.TEST, transform=transforms.ToTensor())\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4, collate_fn=simple_collate_fn)"
   ],
   "id": "a7e246cb438e023d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading labels: 100%|██████████| 1437/1437 [00:00<00:00, 4621.39it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:26.328628Z",
     "start_time": "2024-11-16T09:54:24.410369Z"
    }
   },
   "cell_type": "code",
   "source": "model_yolov5 = torch.hub.load('ultralytics/yolov5', 'custom', path=\"../models/yolov5s.pt\").to(device)",
   "id": "81d310adca9f0de2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Mihai/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-11-15 Python-3.12.0 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 4070 Ti, 12281MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7026307 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:54:26.965181Z",
     "start_time": "2024-11-16T09:54:26.953060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(model, dataloader, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Compute comprehensive metrics for YOLOv5 predictions using sklearn\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing various metrics and plots confusion matrices\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    all_pred_scores = []  # For AUC and mAP\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            batch_size = images.shape[0]\n",
    "\n",
    "            # Get predictions\n",
    "            pred = model(images)\n",
    "\n",
    "            # Process each image in batch\n",
    "            for idx in range(batch_size):\n",
    "                # Get predictions for single image\n",
    "                single_pred = pred[idx]\n",
    "                single_true_labels = torch.zeros(6)  # 6 classes\n",
    "                for label in labels[idx]:\n",
    "                    single_true_labels[label] = 1\n",
    "\n",
    "                # Get confidence scores\n",
    "                conf = single_pred[:, 4]\n",
    "\n",
    "                # Get class probabilities\n",
    "                class_probs = single_pred[:, 5:]  # Shape: [25200, 6]\n",
    "\n",
    "                # Get predicted classes and their probabilities\n",
    "                class_scores, class_ids = class_probs.max(1)  # highest class score and index\n",
    "                final_conf = conf * class_scores\n",
    "\n",
    "                # Filter by confidence threshold\n",
    "                mask = final_conf > conf_threshold\n",
    "                filtered_class_ids = class_ids[mask]\n",
    "\n",
    "                # Get maximum probability for each class (for AUC and mAP)\n",
    "                max_probs_per_class = torch.zeros(class_probs.shape[1])\n",
    "                for i in range(class_probs.shape[1]):\n",
    "                    class_mask = class_ids == i\n",
    "                    if class_mask.any():\n",
    "                        max_probs_per_class[i] = (final_conf * class_mask).max()\n",
    "\n",
    "                # Convert predictions to binary format\n",
    "                num_classes = class_probs.shape[1]\n",
    "                pred_labels = torch.zeros(num_classes)\n",
    "\n",
    "                # Mark predicted classes as 1\n",
    "                for class_id in filtered_class_ids:\n",
    "                    pred_labels[class_id] = 1\n",
    "\n",
    "                # Append to overall lists\n",
    "                all_true_labels.append(single_true_labels.cpu().numpy())\n",
    "                all_pred_labels.append(pred_labels.cpu().numpy())\n",
    "                all_pred_scores.append(max_probs_per_class.cpu().numpy())\n",
    "\n",
    "    # Convert lists to arrays\n",
    "    all_true_labels = np.array(all_true_labels)\n",
    "    all_pred_labels = np.array(all_pred_labels)\n",
    "    all_pred_scores = np.array(all_pred_scores)\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {}\n",
    "\n",
    "    # F1, Precision, Recall (per class and averaged)\n",
    "    metrics['f1_per_class'] = f1_score(all_true_labels, all_pred_labels, average=None)\n",
    "    metrics['precision_per_class'] = precision_score(all_true_labels, all_pred_labels, average=None)\n",
    "    metrics['recall_per_class'] = recall_score(all_true_labels, all_pred_labels, average=None)\n",
    "\n",
    "    metrics['f1_macro'] = f1_score(all_true_labels, all_pred_labels, average='macro')\n",
    "    metrics['precision_macro'] = precision_score(all_true_labels, all_pred_labels, average='macro')\n",
    "    metrics['recall_macro'] = recall_score(all_true_labels, all_pred_labels, average='macro')\n",
    "\n",
    "    # mAP and AUC\n",
    "    metrics['mAP_per_class'] = average_precision_score(all_true_labels, all_pred_scores, average=None)\n",
    "    metrics['mAP'] = average_precision_score(all_true_labels, all_pred_scores, average='macro')\n",
    "\n",
    "    # AUC might raise error if some classes don't have both positive and negative examples\n",
    "    try:\n",
    "        metrics['auc_per_class'] = roc_auc_score(all_true_labels, all_pred_scores, average=None)\n",
    "        metrics['auc'] = roc_auc_score(all_true_labels, all_pred_scores, average='macro')\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Could not compute AUC: {e}\")\n",
    "        metrics['auc_per_class'] = np.array([np.nan] * all_true_labels.shape[1])\n",
    "        metrics['auc'] = np.nan\n",
    "\n",
    "    # Confusion Matrix\n",
    "    metrics['confusion_matrices'] = multilabel_confusion_matrix(all_true_labels, all_pred_labels)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\nPer-class metrics:\")\n",
    "    for i in range(all_true_labels.shape[1]):\n",
    "        print(f\"\\nClass {i}:\")\n",
    "        print(f\"F1: {metrics['f1_per_class'][i]:.4f}\")\n",
    "        print(f\"Precision: {metrics['precision_per_class'][i]:.4f}\")\n",
    "        print(f\"Recall: {metrics['recall_per_class'][i]:.4f}\")\n",
    "        print(f\"mAP: {metrics['mAP_per_class'][i]:.4f}\")\n",
    "        print(f\"AUC: {metrics['auc_per_class'][i]:.4f}\")\n",
    "\n",
    "    print(\"\\nOverall metrics:\")\n",
    "    print(f\"Macro F1: {metrics['f1_macro']:.4f}\")\n",
    "    print(f\"Macro Precision: {metrics['precision_macro']:.4f}\")\n",
    "    print(f\"Macro Recall: {metrics['recall_macro']:.4f}\")\n",
    "    print(f\"mAP: {metrics['mAP']:.4f}\")\n",
    "    print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "\n",
    "    # Plot confusion matrices\n",
    "    plot_confusion_matrices(metrics['confusion_matrices'])\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def plot_confusion_matrices(confusion_matrices):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix for each class\n",
    "    \"\"\"\n",
    "    num_classes = len(confusion_matrices)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))  # Adjust layout based on number of classes\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        cm = confusion_matrices[i]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "        axes[i].set_title(f'Class {i}')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('True')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "3262c8567fb01b60",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T09:55:10.154739Z",
     "start_time": "2024-11-16T09:54:28.629647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = compute_metrics(\n",
    "    model=model_yolov5,\n",
    "    dataloader=test_dataloader,\n",
    "    conf_threshold=0.25\n",
    ")"
   ],
   "id": "fdc8caaf24838842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-class metrics:\n",
      "\n",
      "Class 0:\n",
      "F1: 0.9812\n",
      "Precision: 0.9789\n",
      "Recall: 0.9835\n",
      "mAP: 0.9991\n",
      "AUC: 0.9996\n",
      "\n",
      "Class 1:\n",
      "F1: 0.9549\n",
      "Precision: 0.9137\n",
      "Recall: 1.0000\n",
      "mAP: 0.9996\n",
      "AUC: 0.9998\n",
      "\n",
      "Class 2:\n",
      "F1: 0.9969\n",
      "Precision: 0.9938\n",
      "Recall: 1.0000\n",
      "mAP: 1.0000\n",
      "AUC: 1.0000\n",
      "\n",
      "Class 3:\n",
      "F1: 0.6441\n",
      "Precision: 0.4935\n",
      "Recall: 0.9268\n",
      "mAP: 0.7606\n",
      "AUC: 0.9803\n",
      "\n",
      "Class 4:\n",
      "F1: 0.6847\n",
      "Precision: 0.5390\n",
      "Recall: 0.9383\n",
      "mAP: 0.7440\n",
      "AUC: 0.9821\n",
      "\n",
      "Class 5:\n",
      "F1: 0.7812\n",
      "Precision: 0.7463\n",
      "Recall: 0.8197\n",
      "mAP: 0.9122\n",
      "AUC: 0.9933\n",
      "\n",
      "Overall metrics:\n",
      "Macro F1: 0.8405\n",
      "Macro Precision: 0.7775\n",
      "Macro Recall: 0.9447\n",
      "mAP: 0.9026\n",
      "AUC: 0.9925\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Surprise error\n",
    "RuntimeError: stack expects each tensor to be equal size, but got [3, 640, 640] at entry 0 and [3, 500, 500] at entry 14\n",
    "```\n",
    "for i in range(len(dataset)):\n",
    "    assert dataset[i][0].shape == torch.Size([3, 640, 640]), f\"Error at index {i}\"\n",
    "```\n",
    "Using the code above, I've discovered that the image sizes are not consistent. I'll need to resize the images to a common size before passing them to the model."
   ],
   "id": "cad2fd5abe0107c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "718d7353b7d1cfbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
